{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcs6JZ3let6L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihYYnOF3ntzE"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cUDx0h7pnzte",
        "outputId": "c857a669-4a4d-47e8-a95b-dc91dbbf0124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torchtext\n",
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbJIDr8_n1HX"
      },
      "outputs": [],
      "source": [
        "import torchtext.transforms as T\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "padding_idx = 1\n",
        "bos_idx = 0\n",
        "eos_idx = 2\n",
        "max_seq_len = 256\n",
        "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
        "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
        "    T.Truncate(max_seq_len-2),\n",
        "    T.AddToken(token = bos_idx, begin = True),\n",
        "    T.AddToken(token = eos_idx, begin = False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMoNdSlPL_if"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "text_transform_pretrained = torchtext.models.XLMR_BASE_ENCODER.transform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWpdyVrgMY50",
        "outputId": "7d277ae7-75ad-41a0-ae8a-01de12fcc191"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): SentencePieceTokenizer()\n",
              "  (1): VocabTransform(\n",
              "    (vocab): Vocab()\n",
              "  )\n",
              "  (2): Truncate()\n",
              "  (3): AddToken()\n",
              "  (4): AddToken()\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhOfPDThMhXV",
        "outputId": "630c884d-75d1-4a8a-921e-693c405aace9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): SentencePieceTokenizer()\n",
              "  (1): VocabTransform(\n",
              "    (vocab): Vocab()\n",
              "  )\n",
              "  (2): Truncate()\n",
              "  (3): AddToken()\n",
              "  (4): AddToken()\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_transform_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1baqLUeMl5M"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNRlrkrWt6b_"
      },
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "--yhlFyQSMG-",
        "outputId": "82cef365-4771-4cd9-c4b1-d55f692a0e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata==0.5.1\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.1) (1.13.1+cu116)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.1) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata==0.5.1) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (4.0.0)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1 urllib3-1.26.14\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torchdata==0.5.1\n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAmU9fMmuHTf"
      },
      "outputs": [],
      "source": [
        "train_datapipe = SST2(split=\"train\")\n",
        "dev_datapipe = SST2(split=\"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2460BFq2Mrf"
      },
      "outputs": [],
      "source": [
        "tt_datapipe = SST2(split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci5AC-JhGJiV",
        "outputId": "af89592a-b27b-4fd3-9c6e-d17077dddec5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ShardingFilterIterDataPipe"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tt_datapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL6gBp7bGO31",
        "outputId": "beee136d-2c9f-4fa8-bd6b-f42b09eb7d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ShardingFilterIterDataPipe"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DSAe34qquQJ_",
        "outputId": "e173a88f-e11a-4b9e-e194-f0600a6f238c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.13.1+cu116'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5lagg8x158N",
        "outputId": "d0f559d2-0ad0-460d-b401-0c9f8f3bebc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(ShardingFilterIterDataPipe, ShardingFilterIterDataPipe)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datapipe, dev_datapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCSvbfIi2b06",
        "outputId": "8adc1217-9eb2-4a7c-be88-58859ae0b396"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('hide new secretions from the parental units', 0)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_datapipe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ZFy_9O4pDV",
        "outputId": "f10b945c-9ed7-4e33-c270-249e0790a693"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(\"it 's a charming and often affecting journey .\", 1)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(dev_datapipe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0YnkXWZ2fHX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Transform the raw dataset using non-batched API (i.e apply transformation line by line)\n",
        "def apply_transform(x):\n",
        "  return text_transform(x[0]), x[1]\n",
        "\n",
        "train_datapipe = train_datapipe.map(apply_transform)\n",
        "train_datapipe = train_datapipe.batch(batch_size)\n",
        "train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
        "train_dataloader = DataLoader(train_datapipe, batch_size=None)\n",
        "\n",
        "dev_datapipe = dev_datapipe.map(apply_transform)\n",
        "dev_datapipe = dev_datapipe.batch(batch_size)\n",
        "dev_datapipe = dev_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
        "dev_dataloader = DataLoader(dev_datapipe, batch_size=None)\n",
        "\n",
        "tt_datapipe = tt_datapipe.map(apply_transform)\n",
        "tt_datapipe = tt_datapipe.batch(batch_size)\n",
        "tt_datapipe = tt_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
        "tt_dataloader = DataLoader(tt_datapipe, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7mEOMBvAd2p",
        "outputId": "721900ee-03f0-4c60-f382-b9aeb233d531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'token_ids': [[0, 442, 242, 7, 10, 108654, 214, 136, 27983, 52490, 214, 120696, 6, 5, 2], [0, 51, 36361, 19, 59207, 538, 2586, 344, 136, 145342, 13, 2], [0, 114864, 1821, 47, 15673, 450, 110, 1414, 83, 5737, 297, 47, 352, 1299, 92, 10, 13036, 80997, 237, 10, 60091, 14373, 26868, 5844, 1346, 55474, 6, 5, 2], [0, 70, 1030, 1916, 6, 4, 84659, 7, 6, 4, 19612, 6, 4, 27076, 18, 87168, 136, 45730, 621, 756, 237, 16450, 33770, 34475, 70, 36049, 242, 7, 1312, 18864, 83221, 6, 5, 2], [0, 442, 242, 7, 72803, 4210, 4552, 6, 4, 4552, 72803, 6, 5, 2], [0, 102971, 21, 37534, 678, 16000, 136, 10, 10846, 1207, 318, 7844, 116281, 7, 6, 4, 70, 1346, 83, 10, 210651, 214, 538, 85583, 6713, 99, 27150, 24793, 6, 5, 2], [0, 10, 68018, 120, 5670, 223, 1346, 6, 5, 2], [0, 707, 20594, 4568, 6602, 242, 7, 152838, 678, 935, 1119, 9, 2452, 2242, 6, 5, 2], [0, 398, 54, 653, 25, 18, 765, 47, 3714, 1672, 19612, 47, 77947, 70, 1346, 242, 7, 23468, 519, 214, 171759, 111, 180327, 136, 99691, 6, 5, 2], [0, 23, 66161, 17853, 14633, 6, 4, 2684, 111, 3129, 115081, 237, 191975, 237, 2174, 17, 242, 71, 2809, 129842, 24, 12225, 98, 142, 17, 38869, 31, 6, 4, 26168, 8651, 78018, 1295, 569, 71361, 47, 55, 71361, 47, 75, 3055, 2130, 19770, 6, 5, 2], [0, 70, 2409, 1991, 84382, 23718, 7, 111, 70, 37105, 7, 13695, 70, 1346, 61585, 297, 136, 13695, 70, 95771, 68544, 3674, 6, 5, 2], [0, 442, 51776, 10, 114453, 8562, 111, 21, 708, 7432, 47, 509, 67, 70, 12348, 7, 111, 2062, 16466, 100, 1515, 6, 4, 42230, 163, 2514, 6, 4, 1175, 15292, 124249, 6, 4, 136, 25703, 19, 27245, 1518, 66159, 19, 1681, 756, 23, 70, 5701, 14277, 6, 5, 2], [0, 153, 70, 1346, 134729, 7, 1295, 10, 92635, 111, 16000, 15, 9844, 44841, 47, 40197, 1810, 70, 95319, 1388, 153, 2], [0, 642, 74855, 100, 15, 40361, 136, 249, 202, 1388, 6, 4, 3853, 1884, 2856, 6, 4, 21208, 95134, 442, 242, 7, 142, 112019, 20903, 42, 47, 13380, 53, 6, 5, 2], [0, 3853, 92973, 35992, 1221, 2684, 47041, 959, 7413, 2367, 1836, 242, 107, 191618, 678, 63134, 11907, 5155, 2819, 70, 14277, 21, 22824, 15044, 6, 68332, 42458, 136, 16000, 6, 5, 2], [0, 10, 206986, 6, 4, 11192, 9, 154336, 297, 24668, 1295, 68360, 450, 201602, 21286, 171759, 7, 19612, 6, 4, 82393, 6, 4, 11531, 6, 4, 136, 11192, 23134, 6, 5, 2]], 'target': [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/datapipes/iter/combining.py:262: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "for batch in dev_dataloader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBEqY3zOIJCP",
        "outputId": "6d213591-1a86-4c0d-dbed-232a0726f6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'token_ids': [[0, 1274, 112, 3525, 23410, 17514, 1295, 70, 49129, 289, 25072, 7, 2], [0, 70541, 7, 110, 43198, 6, 4, 4734, 27554, 71, 914, 9405, 2], [0, 450, 5161, 7, 6863, 124850, 136, 6, 127219, 1636, 9844, 43257, 34923, 1672, 14135, 31425, 2], [0, 47143, 7, 75, 3055, 538, 214521, 47, 47143, 70, 5701, 87420, 2], [0, 98, 70, 130481, 52758, 429, 9, 4390, 9, 2347, 9, 1679, 6468, 221115, 7, 70, 1346, 114014, 5809, 17745, 61007, 1257, 2], [0, 450, 242, 7, 2060, 5792, 187641, 47, 75688, 6044, 158788, 39734, 2], [0, 106804, 90, 450, 70, 14364, 111, 6044, 206686, 46389, 978, 37499, 237, 65842, 27528, 831, 7464, 15504, 1810, 10, 19336, 6, 4, 3357, 1346, 678, 142, 88965, 58982, 2146, 6, 5, 2], [0, 111, 858, 2408, 2], [0, 10, 8, 11856, 297, 809, 18266, 33, 9, 46799, 9, 18345, 242, 7, 215612, 141, 30260, 1294, 2], [0, 621, 1286, 53894, 538, 17569, 8305, 3501, 23, 2684, 9473, 7108, 9, 201950, 214, 242, 54180, 2], [0, 60899, 47, 48152, 140909, 7, 2], [0, 100, 8382, 14277, 519, 1314, 2750, 186992, 450, 9473, 1836, 54, 653, 25, 18, 3249, 72304, 1884, 1836, 11814, 47, 176683, 2], [0, 70, 2831, 7440, 33720, 242, 7, 123087, 6, 4, 2], [0, 24124, 3642, 6494, 903, 14277, 509, 2], [0, 6, 50771, 3060, 109989, 939, 47, 10, 115, 6492, 13765, 2], [0, 70, 158036, 19612, 72004, 2]], 'target': [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]}\n"
          ]
        }
      ],
      "source": [
        "for batch in tt_dataloader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7b25945ece2c4d2981f3192596fbf4f9",
            "f4660df1abfd4afeb1f1ed410a6f6704",
            "ffe8ac490fcf46019a64867b99904cb1",
            "75e5e3edc42d4cf9a5e1f6ed0bb2e092",
            "641d8ef2b67f45d59c41999bb809ed53",
            "a59c90132c3249b4951ef2b90ec9b5fc",
            "b0f9146736ab47558fbc3c3c80768de5",
            "b2a64f11b64f4baa9c1faa9400f2afc1",
            "8fff52b2f2cb498486674686a8e7a93c",
            "a71caef48af448e7921d06585d1031db",
            "7731790bf5e7471a824c667ab6026008"
          ]
        },
        "id": "XdIa7WLj8hX8",
        "outputId": "39676c35-4b4f-4ca5-a912-664eafd55227"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/text/xlmr.base.encoder.pt\" to /root/.cache/torch/hub/checkpoints/xlmr.base.encoder.pt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b25945ece2c4d2981f3192596fbf4f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (encoder): RobertaEncoder(\n",
              "    (transformer): TransformerEncoder(\n",
              "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
              "      (layers): TransformerEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (3): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (4): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (5): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (6): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (7): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (8): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (9): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (10): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (11): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (positional_embedding): PositionalEmbedding(\n",
              "        (embedding): Embedding(514, 768, padding_idx=1)\n",
              "      )\n",
              "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (head): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "    (activation_fn): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = 2\n",
        "input_dim = 768\n",
        "\n",
        "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
        "\n",
        "classifier_head = RobertaClassificationHead(num_classes = 2, input_dim = input_dim)\n",
        "model = XLMR_BASE_ENCODER.get_model(head = classifier_head)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjMPR5Xh-MkB"
      },
      "outputs": [],
      "source": [
        "import torchtext.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch import nn\n",
        "\n",
        "lr = 1e-5\n",
        "optimizer = AdamW(model.parameters(), lr = lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_step(input, target):\n",
        "  output = model(input)\n",
        "  loss = loss_fn(output, target)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "def eval_step(input, target):\n",
        "  output = model(input)\n",
        "  loss = loss_fn(output, target)\n",
        "  return loss, (output.argmax(1) == target).type(torch.float).sum()\n",
        "\n",
        "def evaluating():\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "  counter = 0\n",
        "  with torch.inference_mode():\n",
        "    for batch in dev_dataloader:\n",
        "      input = F.to_tensor(batch[\"token_ids\"], padding_value = padding_idx).to(device)\n",
        "      target = torch.tensor(batch[\"target\"]).to(device)\n",
        "      loss, predictions = eval_step(input, target)\n",
        "      total_loss += loss\n",
        "      correct_predictions += predictions\n",
        "      total_predictions += len(target)\n",
        "      counter += 1\n",
        "      break\n",
        "  return total_loss/counter, correct_predictions/total_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cbtzJawRyE0",
        "outputId": "fb82a804-2ce7-4638-cf79-5852a5d3547f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/transformer.py:276: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:175.)\n",
            "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
            "100%|██████████| 1/1 [15:28<00:00, 928.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 | loss : 0.06217917799949646 | accuracy : 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 1\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  for batch in train_dataloader:\n",
        "    input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(device)\n",
        "    target = torch.tensor(batch[\"target\"]).to(device)\n",
        "    train_step(input, target)\n",
        "\n",
        "  loss, accuracy = evaluating()\n",
        "  print(f\"Epoch : {epoch} | loss : {loss} | accuracy : {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"It's very bad\""
      ],
      "metadata": {
        "id": "JB3G34a3oC8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnNt7qnVTaW3",
        "outputId": "b6943d65-53ed-459a-85c0-b3d79aac1c36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"It's very bad\", -9999999)"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ],
      "source": [
        "text = (string, -9999999)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1DCInnsy6Oz",
        "outputId": "8e394866-3a1b-46c8-e1dc-00b0e78a7a37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IterableWrapperIterDataPipe"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ],
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "dp = IterableWrapper([text])\n",
        "dp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbrIA7jb_HLJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "dp = dp.sharding_filter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEJikqRdCKJA",
        "outputId": "5ab8d3e6-4c51-404c-ef46-998a2f357853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShardingFilterIterDataPipe"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ],
      "source": [
        "dp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuDPJ0qW4mSo",
        "outputId": "dd574850-712b-4011-bc8d-bba256b93494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"It's very bad\", -9999999)"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ],
      "source": [
        "next(iter(dp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgVA2qYz_R39"
      },
      "outputs": [],
      "source": [
        "dp = dp.map(apply_transform)\n",
        "dp = dp.batch(1)\n",
        "dp = dp.rows2columnar([\"token_ids\", \"target\"])\n",
        "dp = DataLoader(dp, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU1OC9ibqOmD",
        "outputId": "9e4f06cb-ac64-463f-df9f-00cbc5a5aa37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'token_ids': [[0, 1650, 25, 7, 4552, 6494, 2]], 'target': [-9999999]}\n"
          ]
        }
      ],
      "source": [
        "for batch in dp:\n",
        "  print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = next(iter(dp))\n",
        "val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw-Gfqduvd60",
        "outputId": "806c3d5a-81e5-4a22-bdbb-0a23eb33a2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': [[0, 1650, 25, 7, 4552, 6494, 2]], 'target': [-9999999]}"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['token_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ccB9c9vkSB",
        "outputId": "609a7f1b-98b0-4dd0-a3bc-309ea72c0444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1650, 25, 7, 4552, 6494, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNRkz8-4Bj7M"
      },
      "outputs": [],
      "source": [
        "input = F.to_tensor(batch[\"token_ids\"], padding_value = padding_idx).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtntgJXoJo94"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  output = model(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZIoZ6jzqaXB",
        "outputId": "1324b5d0-a6e2-409d-9bc2-a12e1ac5378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.5512, -2.1419]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqoSOaVQJr54"
      },
      "outputs": [],
      "source": [
        "ans = output.argmax(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE2locNJ4qyx",
        "outputId": "050ec340-3c7a-4bcc-ba62-a96d319a0ed9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ],
      "source": [
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpXWpBJgp4NZ",
        "outputId": "90c62062-d13f-4225-d45f-9a0c4b341d16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ],
      "source": [
        "ans.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THraTd1lmrH2"
      },
      "outputs": [],
      "source": [
        " try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV4yRd3-q_cj"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('xlmr_base_encoder.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Sj4tlVrjpj",
        "outputId": "18cc00b4-96a6-4a42-b29b-201265b81dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: xlmr_base_encoder.pth (deflated 29%)\n"
          ]
        }
      ],
      "source": [
        "!cd models/ && zip -r ../xlmr_base_encoder.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsUArslWtP8g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGItP1Kb-aQf",
        "outputId": "d4887928-5349-4464-ebd0-b1d28a09393a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving model to: models/xlmr_base_encoder.pth\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "from going_modular.going_modular import utils\n",
        "\n",
        "utils.save_model(\n",
        "    model = model,\n",
        "    target_dir = \"models\",\n",
        "    model_name = \"xlmr_base_encoder.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMGS_gNUxB87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAzQFyR6sJOi",
        "outputId": "d784610d-a7e6-4d68-c4c3-9ef4fcc1e3c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Setup best model filepath\n",
        "model_path = \"models/xlmr_base_encoder.pth\"\n",
        "\n",
        "#  load in the saved state_dict()\n",
        "classifier_head = RobertaClassificationHead(num_classes = 2, input_dim = input_dim)\n",
        "model = XLMR_BASE_ENCODER.get_model(head = classifier_head)\n",
        "\n",
        "# Load the save model state_dict()\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8WxfOssgsqK",
        "outputId": "3a49b190-f63d-4586-9ed6-4bc70db19ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (encoder): RobertaEncoder(\n",
              "    (transformer): TransformerEncoder(\n",
              "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
              "      (layers): TransformerEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (3): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (4): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (5): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (6): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (7): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (8): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (9): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (10): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (11): TransformerEncoderLayer(\n",
              "            (self_attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout1): Dropout(p=0.1, inplace=False)\n",
              "            (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (positional_embedding): PositionalEmbedding(\n",
              "        (embedding): Embedding(514, 768, padding_idx=1)\n",
              "      )\n",
              "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (head): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "    (activation_fn): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).is_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkcCX-j9hH7f",
        "outputId": "50303d3f-3fa5-4735-e8c8-012f960d1cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['bad', 'Good']"
      ],
      "metadata": {
        "id": "8RSdDMuEi6nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRr1o9rmrUMc"
      },
      "outputs": [],
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "from torch.utils.data import DataLoader\n",
        "import torchtext.functional as F\n",
        "from timeit import default_timer as timer\n",
        "# from typing import Tuple, Dict\n",
        "\n",
        "def predict(string):\n",
        "\n",
        "  start_time = timer()\n",
        "\n",
        "  var = (string, -9999999)\n",
        "  dp = IterableWrapper([var])\n",
        "  dp = dp.sharding_filter()\n",
        "\n",
        "  padding_idx = 1\n",
        "  bos_idx = 0\n",
        "  eos_idx = 2\n",
        "  max_seq_len = 256\n",
        "  xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "  xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "\n",
        "  text_transform = T.Sequential(\n",
        "      T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
        "      T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
        "      T.Truncate(max_seq_len-2),\n",
        "      T.AddToken(token = bos_idx, begin = True),\n",
        "      T.AddToken(token = eos_idx, begin = False)\n",
        "  )\n",
        "\n",
        "  # Transform the raw dataset using non-batched API (i.e apply transformation line by line)\n",
        "  def apply_transform(x):\n",
        "    return text_transform(x[0]), x[1]\n",
        "\n",
        "  dp = dp.map(apply_transform)\n",
        "  dp = dp.batch(1)\n",
        "  dp = dp.rows2columnar([\"token_ids\", \"target\"])\n",
        "  dp = DataLoader(dp, batch_size=None)\n",
        "\n",
        "  val = next(iter(dp))\n",
        "  model.to('cpu')\n",
        "  value = F.to_tensor(val[\"token_ids\"], padding_value = padding_idx).to('cpu')\n",
        "    # Pass transformed image through the model and turn the prediction logits into probabilities\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    answer = model(value)\n",
        "  print(answer)\n",
        "  # answer = answer.argmax(1)\n",
        "  answer = torch.softmax(answer, dim=1)\n",
        "  pred_labels_and_probs = {class_names[i]: float(answer[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "\n",
        "  # Calculate pred time\n",
        "  end_time = timer()\n",
        "  pred_time = round(end_time - start_time, 4)\n",
        "\n",
        "  # Return pred dict and pred time\n",
        "  return pred_labels_and_probs, pred_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(\"It's bad\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acysJW_kfruV",
        "outputId": "31bc0546-9792-4d11-8b17-8e2ad4526e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.5530, -2.1476]])\n",
            "({'bad': 0.9909921884536743, 'Good': 0.009007807821035385}, 1.0596)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import gradio as gr\n",
        "except:\n",
        "  !pip -q install gradio\n",
        "  import gradio as gr\n",
        "\n",
        "print(f\"Gradio version : {gr.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-D2i7fdxx6r",
        "outputId": "4211cf31-e11d-4345-d08b-700a9e5b2f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Gradio version : 3.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create title, description and article\n",
        "title = \"Good or Bad\"\n",
        "description = \"Using XLMR_BASE_ENCODER\"\n",
        "# article = \"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/#74-building-a-gradio-interface)\"\n",
        "\n",
        "# Create the gradio demo\n",
        "demo = gr.Interface(\n",
        "    fn = predict, # maps inputs to outputs\n",
        "    inputs = \"textbox\",\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=2, label=\"Predictions\"),\n",
        "        gr.Number(label = \"Prediction time(s) \")\n",
        "    ],\n",
        "    title = title,\n",
        "    description = description,\n",
        "    # article = article\n",
        ")\n",
        "\n",
        "# Launch the demo !\n",
        "demo.launch(\n",
        "    debug = False, # print errors locally ?\n",
        "    share = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "mA1arZwFfz5s",
        "outputId": "aa6e3b63-104c-4033-882a-5b549167ff32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://adf83851-c693-43aa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://adf83851-c693-43aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create path\n",
        "Sentiment_analysis_path = Path(\"demos/Sentiment_analysis\")\n",
        "\n",
        "# Remove files that might exist and create a new directory\n",
        "if Sentiment_analysis_path.exists():\n",
        "  shutil.rmtree(Sentiment_analysis_path)\n",
        "  Sentiment_analysis_path.mkdir(\n",
        "      parents = True,\n",
        "      exist_ok = True\n",
        "  )\n",
        "else:\n",
        "  Sentiment_analysis_path.mkdir(\n",
        "      parents = True,\n",
        "      exist_ok = True\n",
        "  )\n",
        "\n",
        "!ls demos/Sentiment_analysis/"
      ],
      "metadata": {
        "id": "rdC4OVezyCDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create a source path for our target model\n",
        "xlmr_base_encoder_model_path = \"models/xlmr_base_encoder.pth\"\n",
        "\n",
        "# Create a destination path for our target model\n",
        "xlmr_base_encoder_model_destination = Sentiment_analysis_path / xlmr_base_encoder_model_path.split(\"/\")[1]\n",
        "\n",
        "# Try to move the model file\n",
        "try:\n",
        "  print(f\"[INFO] Attempting to move {xlmr_base_encoder_model_path} to {xlmr_base_encoder_model_destination}\")\n",
        "\n",
        "  # Move the model\n",
        "  shutil.move(\n",
        "      src = xlmr_base_encoder_model_path,\n",
        "      dst = xlmr_base_encoder_model_destination\n",
        "  )\n",
        "  print(f\"[INFO] Model move complete.\")\n",
        "# If the model has already been moved, check if it exists\n",
        "except:\n",
        "  print(f\"[INFO] No model found at {xlmr_base_encoder_model_path}, perhaps its already been moved?\")\n",
        "  print(f\"[INFO] Model exist at {xlmr_base_encoder_model_destination} : {xlmr_base_encoder_model_destination.exists()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaQkxzCfzYKS",
        "outputId": "9d505259-e3ea-4e76-b5d1-600252f0604a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Attempting to move models/xlmr_base_encoder.pth to demos/Sentiment_analysis/xlmr_base_encoder.pth\n",
            "[INFO] Model move complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/Sentiment_analysis/requirements.txt\n",
        "torch == 1.13.1\n",
        "torchvision == 0.14.1\n",
        "torchdata == 0.5.1\n",
        "gradio == 3.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VwfWLJW0dsO",
        "outputId": "dc454880-cee1-4fb1-b208-76360cda3013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/Sentiment_analysis/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/Sentiment_analysis/model.py\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
        "from torch import nn\n",
        "def xlmr_base_encoder_model(num_classes:int=2, # default output classes = 2 (Bad, Good)):\n",
        "  # 1, 2, 3 Create EffNetB2 pretrained weights, transforms and model\n",
        "  transforms = torchtext.models.XLMR_BASE_ENCODER.transform()\n",
        "  classifier_head = torchtext.RobertaClassificationHead(num_classes = 2, input_dim = 768)\n",
        "  model = XLMR_BASE_ENCODER.get_model(head = classifier_head)\n",
        "\n",
        "  # 4. Freeze all layers in the base model\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH3y-9CE1jcF",
        "outputId": "af9640cf-b50c-4aee-cc2d-4adbd9ce2047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/Sentiment_analysis/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/Sentiment_analysis/app.py\n",
        "\n",
        "### 1. Imports and class names setup ###\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "import torchtext\n",
        "from model import xlmr_base_encoder_model\n",
        "from timeit import default_timer as timer\n",
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "from torch.utils.data import DataLoader\n",
        "import torchtext.functional as F\n",
        "\n",
        "# Setup class names\n",
        "class_names = [\"Bad\", \"Good\"]\n",
        "\n",
        "### 2. Model and transforms preparation ###\n",
        "model, transforms = xlmr_base_encoder_model(\n",
        "  num_classes = 2\n",
        ")\n",
        "\n",
        "# load save weights\n",
        "model.load_state_dict(\n",
        "  torch.load(\n",
        "    f = \"xlmr_base_encoder.pth\",\n",
        "    map_location = torch.device(\"cpu\") # Load the model to the CPU\n",
        "  )\n",
        ")\n",
        "\n",
        "### 3. Predict function ###\n",
        "\n",
        "def predict(string):\n",
        "\n",
        "  start_time = timer()\n",
        "\n",
        "  var = (string, -9999999)\n",
        "  dp = IterableWrapper([var])\n",
        "  dp = dp.sharding_filter()\n",
        "\n",
        "  padding_idx = 1\n",
        "  bos_idx = 0\n",
        "  eos_idx = 2\n",
        "  max_seq_len = 256\n",
        "  xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "  xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "\n",
        "  text_transform = T.Sequential(\n",
        "      T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
        "      T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
        "      T.Truncate(max_seq_len-2),\n",
        "      T.AddToken(token = bos_idx, begin = True),\n",
        "      T.AddToken(token = eos_idx, begin = False)\n",
        "  )\n",
        "\n",
        "  # Transform the raw dataset using non-batched API (i.e apply transformation line by line)\n",
        "  def apply_transform(x):\n",
        "    return transform(x[0]), x[1]\n",
        "\n",
        "  dp = dp.map(apply_transform)\n",
        "  dp = dp.batch(1)\n",
        "  dp = dp.rows2columnar([\"token_ids\", \"target\"])\n",
        "  dp = DataLoader(dp, batch_size=None)\n",
        "\n",
        "  val = next(iter(dp))\n",
        "  model.to('cpu')\n",
        "  value = F.to_tensor(val[\"token_ids\"], padding_value = padding_idx).to('cpu')\n",
        "    # Pass transformed image through the model and turn the prediction logits into probabilities\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    answer = model(value)\n",
        "  print(answer)\n",
        "  # answer = answer.argmax(1)\n",
        "  answer = torch.softmax(answer, dim=1)\n",
        "  pred_labels_and_probs = {class_names[i]: float(answer[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "\n",
        "  # Calculate pred time\n",
        "  end_time = timer()\n",
        "  pred_time = round(end_time - start_time, 4)\n",
        "\n",
        "  # Return pred dict and pred time\n",
        "  return pred_labels_and_probs, pred_time\n",
        "\n",
        "### 4. Gradio app ###\n",
        "title = \"Good or Bad\"\n",
        "description = \"Using XLMR_BASE_ENCODER\"\n",
        "\n",
        "# Create the gradio demo\n",
        "demo = gr.Interface(\n",
        "    fn = predict, # maps inputs to outputs\n",
        "    inputs = \"textbox\",\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=2, label=\"Predictions\"),\n",
        "        gr.Number(label = \"Prediction time(s) \")\n",
        "    ],\n",
        "    title = title,\n",
        "    description = description,\n",
        "    # article = article\n",
        ")\n",
        "\n",
        "# launch the demo!\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ4CQhMQ3Ri4",
        "outputId": "a0cf6b10-46eb-4a16-8010-7fb07420ac3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/Sentiment_analysis/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd demos/Sentiment_analysis && zip -r ../Sentiment_analysis.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DRuNzjg6rFH",
        "outputId": "9a222ba5-54d7-4210-e0c0-1f226d252a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app.py (deflated 54%)\n",
            "  adding: model.py (deflated 48%)\n",
            "  adding: requirements.txt (deflated 23%)\n",
            "  adding: xlmr_base_encoder.pth (deflated 29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(\"demos/Sentiment_analysis.zip\")\n",
        "except:\n",
        "  print(f\"Not running in Google Colab, can't use google.colab.files.download(), please download Sentiment_analysis.zip manually.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ANqbMS69fI",
        "outputId": "a37bed70-a4c4-43ba-84e6-7f125c76dd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not running in Google Colab, can't use google.colab.files.download(), please download Sentiment_analysis.zip manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHswep2K75pQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "641d8ef2b67f45d59c41999bb809ed53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e5e3edc42d4cf9a5e1f6ed0bb2e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71caef48af448e7921d06585d1031db",
            "placeholder": "​",
            "style": "IPY_MODEL_7731790bf5e7471a824c667ab6026008",
            "value": " 1.03G/1.03G [00:05&lt;00:00, 251MB/s]"
          }
        },
        "7731790bf5e7471a824c667ab6026008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b25945ece2c4d2981f3192596fbf4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4660df1abfd4afeb1f1ed410a6f6704",
              "IPY_MODEL_ffe8ac490fcf46019a64867b99904cb1",
              "IPY_MODEL_75e5e3edc42d4cf9a5e1f6ed0bb2e092"
            ],
            "layout": "IPY_MODEL_641d8ef2b67f45d59c41999bb809ed53"
          }
        },
        "8fff52b2f2cb498486674686a8e7a93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a59c90132c3249b4951ef2b90ec9b5fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71caef48af448e7921d06585d1031db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f9146736ab47558fbc3c3c80768de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a64f11b64f4baa9c1faa9400f2afc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4660df1abfd4afeb1f1ed410a6f6704": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59c90132c3249b4951ef2b90ec9b5fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f9146736ab47558fbc3c3c80768de5",
            "value": "100%"
          }
        },
        "ffe8ac490fcf46019a64867b99904cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a64f11b64f4baa9c1faa9400f2afc1",
            "max": 1109857305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fff52b2f2cb498486674686a8e7a93c",
            "value": 1109857305
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}